ğŸŒ€ NETRAX AI - à¤¨à¥‡à¤¤à¥à¤°à¤ƒ
Human-Motion Driven Personal Assistant

Gesture-controlled â€¢ Body-aware â€¢ JARVIS-inspired

NETRAX AI (pronounced as, "à¤¨à¥‡à¤¤à¥à¤°à¤ƒ") is an advanced, real-time body detection + gesture recognition system designed to integrate directly with a personal AI assistant.
Using MediaPipe Holistic, custom gesture recognition logic, and a modular adapter, NETRAX AI transforms human motion into commands.

Whether you raise a hand, make a peace sign, swipe your arm, or lean your body â€” NETRAX detects it and routes it as a precise command to your JARVIS-style system.

ğŸ“Œ Features
ğŸ”¥ 60+ Keypoint Body Tracking

Powered by MediaPipe Holistic (pose + hands + face landmarks).

âœ‹ Hand Gesture Recognition

Supports:

Peace âœŒï¸

Stop/Open-Palm âœ‹

Fist âœŠ

Thumbs Up ğŸ‘

Thumbs Down ğŸ‘

Point ğŸ‘‰

Open Palm

Combined/multi-hand gestures

ğŸ§â€â™‚ï¸ Full-Body Pose Detection

Arms crossed

Arms up

Lean left/right

Pause pose

Zoom in/out (two-hand)

ğŸ§­ Motion Tracking (Swipe Gestures)

Swipe Left

Swipe Right

Swipe Up

Swipe Down

ğŸ”„ Headless + Modular Integration

NETRAX AI integrates with any AI assistant via:

Callback mode

Queue mode

Event bus mode

âš¡ High-Performance Tracking

One-Euro filter smoothing

Moving average & exponential filters

Frame skipping for high FPS

Visualization mode with real-time FPS overlay

ğŸ§± Project Structure
NETRAX_AI/
â”‚â”€â”€ jarvis.py
â”‚â”€â”€ run_jarvis.py
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ README.md
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ body_detection_config.json
â”‚   â””â”€â”€ gesture_mappings.json
â”‚
â””â”€â”€ modules/
    â””â”€â”€ body_detection/
        â”œâ”€â”€ __init__.py
        â”œâ”€â”€ body_detection.py
        â”œâ”€â”€ camera.py
        â”œâ”€â”€ gesture.py
        â”œâ”€â”€ pose.py
        â”œâ”€â”€ tracking.py
        â”œâ”€â”€ adapter.py
        â”œâ”€â”€ jarvis_integration.py
        â”œâ”€â”€ test_body_detection.py
        â””â”€â”€ preview_camera.py

âš™ï¸ Installation
1ï¸âƒ£ Install Python 3.11 (recommended)

MediaPipe does NOT support Python 3.13.

2ï¸âƒ£ Create a virtual environment
py -3.11 -m venv venv
venv\Scripts\activate

3ï¸âƒ£ Install dependencies
pip install --upgrade pip
pip install -r requirements.txt

4ï¸âƒ£ (Optional) Use DroidCam as main camera

If you want to use your phone camera:

Install DroidCam PC + mobile app

Start the feed

Run preview_camera.py to find the correct camera index

Set "camera_id": X in config/body_detection_config.json

ğŸ® Usage
â–¶ï¸ Run the Body Detection Standalone
cd modules/body_detection
python jarvis_integration.py

â–¶ï¸ Run NETRAX AI fully integrated with your JARVIS core
python run_jarvis.py


This opens the visualization window and routes recognized gestures directly into your JARVIS assistant.

Press:

Q â†’ Quit

P â†’ Pause body detection

ğŸ–ï¸ Available Gestures & Actions
Gesture	Action
Peace âœŒï¸	screenshot
Stop âœ‹	pause_media
Fist âœŠ	mute
Thumbs Up ğŸ‘	volume_up
Thumbs Down ğŸ‘	volume_down
Point ğŸ‘‰	select
Swipe Left â†’	previous_track
Swipe Right â†	next_track
Swipe Up â†‘	scroll_up
Swipe Down â†“	scroll_down
Arms Crossed	lock_screen
Arms Up	pause_detection
Lean Left	switch_workspace(left)
Lean Right	switch_workspace(right)
Zoom In	zoom_in
Zoom Out	zoom_out
ğŸ§  How It Works

NETRAX AI consists of four main layers:

1ï¸âƒ£ Camera Layer

Captures frames with minimal latency using a threaded OpenCV stream.

2ï¸âƒ£ Pose Detection Layer

Uses MediaPipe Holistic to extract:

33 body landmarks

21 left-hand landmarks

21 right-hand landmarks

Key face landmarks

3ï¸âƒ£ Gesture Recognition Layer

Processes pose data into gestures using:

Finger-state analysis

Body-angle analysis

Motion vector tracking

Swipe direction logic

Gesture-hold timing filters

4ï¸âƒ£ Integration Adapter

Converts gestures â†’ high-level commands like:

volume_up
pause_media
scroll_down
screenshot


These are then sent to your JARVIS system.

ğŸŒ Why "NETRAX AI"?

NETRAX comes from:
NETRA (Sanskrit: â€œeye / visionâ€) + X (hyper-extension, unknown, futuristic).

Meaning:

"The AI that sees."

Perfect for a vision-driven, gesture-aware personal assistant.

ğŸš€ Roadmap

 Face expression recognition

 Hand pose refinement

 Natural language + gesture fusion

 Multi-user gesture support

 AR/Hologram UI integration

ğŸ“œ License

This project is for personal educational & experimental use.
Modify freely.
